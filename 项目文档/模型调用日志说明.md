# 模型调用过程日志说明

本文档详细说明了系统中所有模型调用相关的日志点，帮助开发者追踪和调试模型调用过程。

## 日志标记前缀

系统使用以下前缀来标识不同类型的日志：
- `[MODEL]` - 模型加载相关
- `[LLM]` - LLM 调用相关
- `[CONTEXT]` - 上下文构建相关
- `[CHAT]` - 聊天请求处理相关
- `[RERANK]` - 文档重排序相关
- `[UPLOAD]` - 文件上传相关

## 1. 模型加载日志

### 1.1 聊天模型加载 (`src/lib/models/registry.ts`)

```
[MODEL] ===== 开始加载聊天模型 =====
[MODEL] Provider ID: <provider_id>
[MODEL] Model Name: <model_name>
[MODEL] Provider 名称: <provider_name>
[MODEL] Provider 类型: <provider_type>
[MODEL] 调用 provider.loadChatModel...
[MODEL] 聊天模型加载成功（耗时: <duration>ms）
[MODEL] ===== 聊天模型加载完成 =====
```

### 1.2 嵌入模型加载 (`src/lib/models/registry.ts`)

```
[MODEL] ===== 开始加载嵌入模型 =====
[MODEL] Provider ID: <provider_id>
[MODEL] Model Name: <model_name>
[MODEL] Provider 名称: <provider_name>
[MODEL] Provider 类型: <provider_type>
[MODEL] 调用 provider.loadEmbeddingModel...
[MODEL] 嵌入模型加载成功（耗时: <duration>ms）
[MODEL] ===== 嵌入模型加载完成 =====
```

## 2. LLM 调用流程日志

### 2.1 搜索和回答入口 (`src/lib/search/metaSearchAgent.ts`)

```
[LLM] ===== 开始 LLM 搜索和回答流程 =====
[LLM] 查询内容: <query_preview>
[LLM] 历史消息数量: <history_count>
[LLM] 优化模式: <optimization_mode>
[LLM] 文件ID数量: <file_count>
[LLM] 创建回答链...
[LLM] 回答链创建完成（耗时: <duration>ms）
[LLM] 开始流式调用 LLM...
[LLM] LLM 流式调用已启动（耗时: <duration>ms）
[LLM] ===== LLM 搜索和回答流程完成（总耗时: <duration>ms）=====
```

### 2.2 搜索检索链创建 (`src/lib/search/metaSearchAgent.ts`)

```
[LLM] ===== 创建搜索检索链 =====
[LLM] 设置搜索检索链 LLM 温度为 0
```

### 2.3 搜索检索链 LLM 调用 (`src/lib/search/metaSearchAgent.ts`)

```
[LLM] ===== 处理搜索检索链 LLM 输出 =====
[LLM] LLM 输出长度: <output_length>
[LLM] 解析完成，链接数量: <link_count>
[LLM] 提取的问题: <question_preview>
[LLM] 解析耗时: <duration>ms
```

### 2.4 网络搜索执行时的 LLM 调用 (`src/lib/search/metaSearchAgent.ts`)

```
[CONTEXT] 执行网络搜索...
[LLM] 调用搜索检索链 LLM...
[LLM] 搜索检索链 LLM 调用完成（耗时: <duration>ms）
[CONTEXT] 网络搜索结果，文档数量: <doc_count>
```

### 2.5 文档摘要 LLM 调用 (`src/lib/search/metaSearchAgent.ts`)

当进行网络搜索并需要摘要时：

```
[LLM] 开始批量调用 LLM 进行文档摘要，文档数量: <doc_count>
[LLM] [<index>/<total>] 开始摘要文档: <doc_title>
[LLM] [<index>/<total>] 文档摘要完成（耗时: <duration>ms），摘要长度: <summary_length> 字符
[LLM] 所有文档摘要完成（总耗时: <duration>ms），摘要文档数: <summary_count>
```

### 2.6 最终响应生成 LLM 调用 (`src/lib/search/metaSearchAgent.ts`)

```
[LLM] ===== 准备调用 LLM 生成最终响应 =====
[LLM] Prompt 消息数量: <message_count>
[LLM] 最后一条用户消息预览: <message_preview>
[LLM] 开始调用 LLM...
```

## 3. 流式响应处理日志

### 3.1 流式响应处理 (`src/lib/search/metaSearchAgent.ts`)

```
[LLM] ===== 开始处理流式响应 =====
[LLM] 收到第一个响应块（耗时: <time_to_first_chunk>ms）
[LLM] 已处理 <chunk_count> 个响应块
[LLM] 上下文检索完成，发送来源信息
[LLM] 流式响应完成（总耗时: <total_duration>ms，首块时间: <first_chunk_time>ms，总块数: <total_chunks>）
[LLM] ===== 流式响应处理完成 =====
```

## 4. 上下文构建日志

### 4.1 上下文构建过程 (`src/lib/search/metaSearchAgent.ts`)

```
[CONTEXT] ===== 开始构建上下文 =====
[CONTEXT] 查询: <query>
[CONTEXT] 文件ID: <file_ids>
[CONTEXT] 是否搜索网络: <search_web>
[CONTEXT] 执行网络搜索... / [CONTEXT] 跳过网络搜索
[CONTEXT] 开始重新排序文档...
[CONTEXT] 重新排序完成，返回文档数量: <doc_count>
[CONTEXT] ===== 上下文构建完成 =====
```

## 5. 聊天请求处理日志

### 5.1 聊天请求入口 (`src/app/api/chat/route.ts`)

```
[CHAT] ===== 开始处理聊天请求 =====
[CHAT] 消息内容: <message_preview>
[CHAT] 聊天ID: <chat_id>
[CHAT] 焦点模式: <focus_mode>
[CHAT] 优化模式: <optimization_mode>
[CHAT] 上传的文件ID: <file_ids>
[CHAT] 历史消息数量: <history_count>
[CHAT] 加载模型...
[CHAT] 聊天模型 Provider ID: <provider_id>
[CHAT] 聊天模型 Key: <model_key>
[CHAT] 嵌入模型 Provider ID: <embedding_provider_id>
[CHAT] 嵌入模型 Key: <embedding_model_key>
[CHAT] 模型加载完成
[CHAT] 用户消息ID: <message_id>
[CHAT] 历史消息处理完成，消息数量: <history_count>
[CHAT] 开始搜索和回答...
[CHAT] 传递给处理器的文件ID: <file_ids>
[CHAT] 搜索和回答完成，开始流式返回
```

## 6. 性能指标说明

所有日志中都包含了耗时信息，帮助识别性能瓶颈：

### 关键性能指标

1. **模型加载时间** (`[MODEL]`)
   - 聊天模型加载耗时
   - 嵌入模型加载耗时

2. **LLM 调用时间** (`[LLM]`)
   - 搜索检索链 LLM 调用耗时
   - 文档摘要 LLM 调用耗时
   - 最终响应生成 LLM 调用耗时

3. **流式响应指标** (`[LLM]`)
   - 首块响应时间（Time to First Chunk）
   - 总响应时间
   - 响应块总数

4. **总体流程时间** (`[LLM]`)
   - 整个搜索和回答流程的总耗时

## 7. 日志使用建议

### 7.1 调试模型加载问题

当模型加载失败时，查看：
- `[MODEL]` 日志中的 Provider 信息
- 模型加载耗时
- 错误详情

### 7.2 调试 LLM 调用问题

当 LLM 调用异常时，查看：
- `[LLM]` 日志中的调用流程
- 各阶段的耗时
- Prompt 消息数量和内容预览

### 7.3 性能优化

分析性能时，关注：
- 模型加载耗时是否过长
- LLM 调用各阶段的耗时分布
- 首块响应时间
- 总响应时间

### 7.4 调试上下文构建

当回答质量不佳时，查看：
- `[CONTEXT]` 日志中的文档数量
- 是否执行了网络搜索
- 文档重排序结果

## 8. 日志示例

完整的模型调用流程日志示例：

```
[CHAT] ===== 开始处理聊天请求 =====
[CHAT] 消息内容: 什么是人工智能？
[CHAT] 加载模型...
[MODEL] ===== 开始加载聊天模型 =====
[MODEL] Provider ID: openai
[MODEL] Model Name: gpt-4
[MODEL] 聊天模型加载成功（耗时: 234ms）
[MODEL] ===== 开始加载嵌入模型 =====
[MODEL] 嵌入模型加载成功（耗时: 156ms）
[CHAT] 模型加载完成
[LLM] ===== 开始 LLM 搜索和回答流程 =====
[LLM] 创建回答链...
[CONTEXT] ===== 开始构建上下文 =====
[CONTEXT] 是否搜索网络: true
[LLM] 调用搜索检索链 LLM...
[LLM] 搜索检索链 LLM 调用完成（耗时: 1234ms）
[CONTEXT] 网络搜索结果，文档数量: 5
[LLM] 开始批量调用 LLM 进行文档摘要，文档数量: 5
[LLM] [1/5] 文档摘要完成（耗时: 890ms）
...
[LLM] 所有文档摘要完成（总耗时: 3456ms）
[CONTEXT] 重新排序完成，返回文档数量: 5
[LLM] 准备调用 LLM 生成最终响应 =====
[LLM] 开始流式调用 LLM...
[LLM] ===== 开始处理流式响应 =====
[LLM] 收到第一个响应块（耗时: 890ms）
[LLM] 流式响应完成（总耗时: 12345ms，首块时间: 890ms，总块数: 156）
[LLM] ===== LLM 搜索和回答流程完成（总耗时: 15678ms）=====
```

## 9. 注意事项

1. **日志输出位置**：所有日志都会输出到服务器控制台
2. **日志格式**：使用统一的 `[PREFIX]` 格式便于过滤和搜索
3. **性能影响**：日志输出对性能影响很小，但在高并发场景下可能需要控制日志级别
4. **敏感信息**：日志中不包含 API 密钥等敏感信息，但可能包含部分用户查询内容

## 10. 未来改进

计划添加的功能：
- 日志级别控制（DEBUG、INFO、WARN、ERROR）
- 日志文件输出
- 结构化日志格式（JSON）
- 日志聚合和分析工具集成

